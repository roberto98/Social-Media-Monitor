{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f544ffc-1390-4056-b2ce-d0e9da4f0cac",
   "metadata": {},
   "source": [
    "# Social Media Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c807eee-6edf-446c-8302-da94aa9e70bf",
   "metadata": {},
   "source": [
    "In this project i'll implement a social media monitor that tracks topics or trends from social media or blogs. This project can help businesses or individuals stay up-to-date with the latest developments and discussions related to their areas of interest.\n",
    "\n",
    "To implement this project, I'll follow these steps:\n",
    "\n",
    "- **1. Data Collection:** Gather data from various sources like news websites, blogs, and social media using APIs or web scraping techniques or RSS feed. In this case I'll use the 20newsgroups dataset from Sklearn that comprises around 18000 newsgroups posts on 20 topics.\n",
    "- **2. Text Preprocessing:** Clean and normalize the text data using stopword removal, stemming and lemmatization.\n",
    "- **3. Topic Modeling:** Employ topic modeling techniques like Latent Dirichlet Allocation (LDA) to identify the main topics or themes present in the collected data. This will help filter relevant content based on the topics of interest.\n",
    "- **4. Sentiment Analysis:** Determine the sentiment of the content (positive, negative, or neutral) using a rule-based approach like VADER sentiment analyzer.\n",
    "- **5. Summarization:** Generate summaries of the relevant content using extractive summarization based on word frequencies, so that users can quickly grasp the main points without reading the entire text.\n",
    "- **6. Visualization and Reporting:** Visualize the results in an intuitive dashboard or report format, showing the distribution of topics, sentiment scores, and summaries of the relevant content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2a2ee-b7b3-4d83-92f1-6eada6776a96",
   "metadata": {},
   "source": [
    "# **0. Import libraries:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbe65e-86d5-4379-9ddd-f036ba5453bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install nltk\n",
    "%pip install gensim\n",
    "%pip install pyLDAvis\n",
    "%pip install vaderSentiment\n",
    "%pip install wordcloud\n",
    "%pip install matplotlib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc297b-6397-49e9-b2c7-4e383dfa9c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(42)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# --------------- Dataset ------------- #\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# --------------- Pre-Processing -------- #\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "# --------------- LDA Model ---------- #\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "# --------------- Sentiment Analysis --------- #\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "# --------------- \n",
    "\n",
    "# --------------- Visualize and Report ----------- #\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e656e-b9db-4705-84ea-edf8844b994c",
   "metadata": {},
   "source": [
    "# **1. Data Collection:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d688647-8e11-458e-9898-c9b55b3a8cf0",
   "metadata": {},
   "source": [
    "Data can be collected from various sources like news websites, blogs, and social media using APIs or web scraping techniques or RSS feed. In this case I use the 20newsgroups dataset from Sklearn, which is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups.\n",
    "More informations can be found at this [link](http://qwone.com/~jason/20Newsgroups/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08affa98-8e7d-4386-85e9-14cad963c1e0",
   "metadata": {},
   "source": [
    "**Exploring the 20newsgroups dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198dca9c-e1ff-4ac7-ba1e-edfbc9eb9d52",
   "metadata": {},
   "source": [
    "First, I remove the headers, footers and quotes from the texts. The difference between the original text and the clean text that I'll use for my experiments are showed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3616e836-2491-44a4-af13-6d7780cf87a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_text = fetch_20newsgroups(subset='test', categories=['sci.space'])\n",
    "print(f\"Original text:\\n{example_text.data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4e757-b1ca-4354-9fab-7a93da506d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_example_text = fetch_20newsgroups(subset='test', categories=['sci.space'], remove=('headers', 'footers', 'quotes'))\n",
    "print(f\"Clean text:\\n{clean_example_text.data[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a874892-9cf4-4936-a6a0-1a224f162b95",
   "metadata": {},
   "source": [
    "Then, I check that the training topics are balanced, so there isn't bias during the training of the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98273d9-fff1-473e-ad37-686a1a7b6579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify train dataset is balanced\n",
    "motorcycles_train = fetch_20newsgroups(subset='train', categories=['rec.motorcycles'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Motorcycles dataset size: \", len(motorcycles_train.data))\n",
    "\n",
    "hardware_train = fetch_20newsgroups(subset='train', categories=['comp.sys.ibm.pc.hardware'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Hardware dataset size: \", len(hardware_train.data))\n",
    "\n",
    "graphics_train = fetch_20newsgroups(subset='train', categories=['comp.graphics'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Graphics dataset size: \", len(graphics_train.data))\n",
    "\n",
    "med_train = fetch_20newsgroups(subset='train', categories=['sci.med'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Med dataset size: \", len(med_train.data))\n",
    "\n",
    "space_train = fetch_20newsgroups(subset='train', categories=['sci.space'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Space dataset size: \", len(space_train.data))\n",
    "\n",
    "guns_train = fetch_20newsgroups(subset='train', categories=['talk.politics.guns'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Guns dataset size: \", len(guns_train.data))\n",
    "\n",
    "crypt_train = fetch_20newsgroups(subset='train', categories=['sci.crypt'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Crypt dataset size: \", len(crypt_train.data))\n",
    "\n",
    "forsale = fetch_20newsgroups(subset='train', categories=['misc.forsale'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Forsale dataset size: \", len(forsale.data))\n",
    "\n",
    "christian = fetch_20newsgroups(subset='train', categories=['soc.religion.christian'], remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Christian dataset size: \", len(christian.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644a0ff-7883-4584-8e7a-024f22d79e7d",
   "metadata": {},
   "source": [
    "**Train dataset creation**\n",
    "\n",
    "I create the train dataset. In this case I consider only 4 training topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313f6d9-7343-4879-81a0-9af81cb22650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create train dataset with selected categories\n",
    "train_categories = ['talk.religion.misc', 'rec.autos', 'comp.graphics', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=train_categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print(newsgroups_train.target_names)\n",
    "\n",
    "n=30\n",
    "print(f\"Topics of first {n} texts: {newsgroups_train.target[:n]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59960efa-a459-49d0-bed2-6d91702e2f4d",
   "metadata": {},
   "source": [
    "**Test dataset creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3904b5-5d37-4e00-9ab8-f1172e5f0426",
   "metadata": {},
   "source": [
    "For the test set, I create a custom dataset composed by 100 documents and 2 topics: 70% rec.autos and 30% sci.space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61170b2a-afdf-477f-a3f2-da74523e9b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create test dataset with 100 samples: 70% guns and 20% space and 10% med\n",
    "n_test_docs = 100\n",
    "n_docs_70 = int(n_test_docs * 0.7)\n",
    "n_docs_30 = n_test_docs - n_docs_70\n",
    "\n",
    "# Fetch data for each category\n",
    "test_70 = fetch_20newsgroups(subset='test', categories=['sci.space'], remove=('headers', 'footers', 'quotes'))\n",
    "test_30 = fetch_20newsgroups(subset='test', categories=['comp.graphics'], remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Randomly select the desired number of documents from each category\n",
    "docs70_indices = np.random.choice(len(test_70.data), n_docs_70, replace=False)\n",
    "docs30_indices = np.random.choice(len(test_30.data), n_docs_30, replace=False)\n",
    "\n",
    "# Create the test dataset\n",
    "test_data = [test_70.data[i] for i in docs70_indices] + [test_30.data[i] for i in docs30_indices]\n",
    "\n",
    "\"\"\"\n",
    "test_target = np.concatenate((guns_test.target[docs70_indices], space_test.target[docs20_indices], med_test.target[docs10_indices]))\n",
    "\n",
    "# Create the newsgroups_test dataset\n",
    "newsgroups_test = {\n",
    "    'data': test_data,\n",
    "    'target': test_target,\n",
    "    'target_names': ['talk.politics.guns', 'sci.space', 'sci.med']\n",
    "}\n",
    "\"\"\"\n",
    "#print(\"Newsgroups test dataset size: \", len(newsgroups_test['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09b4ca-6e40-42ea-8651-b096592ff444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(test_data[96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e6e70-ea46-437a-933b-4c36c5603d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Train dataset size: \", len(newsgroups_train.data))\n",
    "print(\"Train topics are:\\n\",newsgroups_train.target_names)\n",
    "\n",
    "print(\"\\nTest dataset size: \", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51b685-8c16-42eb-b823-7824e7055ad5",
   "metadata": {},
   "source": [
    "# **2. Text Preprocessing:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5ac49-7f54-4e52-8939-7a1f71fa0df0",
   "metadata": {},
   "source": [
    "I clean and normalize the text data using tokenization, stopword removal, and stemming/lemmatization. I use the `nltk` library for these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55868e82-bb4d-4517-929d-b4303ef2372c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(data):\n",
    "    # Remove punctuation and stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def tokenize(text):\n",
    "        return [word for word in word_tokenize(text.lower()) if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    def lemmatize(text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(word) for word in text]\n",
    "\n",
    "    # Tokenization\n",
    "    tokenized_data = [tokenize(text) for text in data]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_data = [[stemmer.stem(token) for token in text] for text in tokenized_data]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatized_data = [lemmatize(text) for text in tokenized_data]\n",
    "\n",
    "    return stemmed_data, lemmatized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d0439-7fdd-4fe0-94a5-5c5187f04e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess train dataset\n",
    "stemmed_train_data, lemmatized_train_data = preprocess_text(newsgroups_train.data)\n",
    "\n",
    "# Preprocess test dataset\n",
    "stemmed_test_data, lemmatized_test_data = preprocess_text(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053fc7b-6a85-4cf7-8d3f-9c4bf489c239",
   "metadata": {},
   "source": [
    "Let's visualize the difference between a stemmed text and a lemmatized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bf5d2-7ee1-46f8-997f-3b0c958f0549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(stemmed_train_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae15115-95df-4a7b-9df3-57bae75167db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(lemmatized_train_data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19967faa-f869-497b-beea-bdf329f79f5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **3. Topic Modeling:** \n",
    "Apply Latent Dirichlet Allocation (LDA) to identify the main topics in the collected data. In this part I'll use a scratch implementation and compare it with `gensim` library version. To evaluate both models on the testing set I compute the coherence scores.\n",
    "\n",
    "Remember, for topic modeling, you can train your model on any similar corpus of text documents. It doesn't necessarily have to contain the same topics as your unseen documents but having some overlap would likely improve performance. For example, if you're looking to categorize social media posts from a specific platform or about a specific subject, you would ideally use a training set gathered from the same or similar platform/subject.\n",
    "\n",
    "However, if you want to train an LDA model on the specific topics you mentioned, you would need a dataset that contains a substantial number of documents related to these topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af215bc7-7375-4f5e-8f35-bb80c39ad4ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf18aa-5e2f-445f-89a9-bc8d498bbfbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Latent Dirichlet Allocation (LDA) is a generative probabilistic model used in topic modeling. It is a statistical model that allows us to discover latent topics within a collection of documents. LDA assumes that each document in the collection is a mixture of various topics, and each topic is a distribution over words.\n",
    "\n",
    "It's an unsupervised learning method, meaning that it generates a probabilistic model to identify groups of topics without the need for known class labels. It uses only the distribution of words to mathematically model topic.\n",
    "\n",
    "Here's a step-by-step explanation of how LDA works:\n",
    "\n",
    "1. **Initialization**: Choose the number of topics K to extract from the document collection and randomly assign each word in each document to one of the K topics.\n",
    "\n",
    "2. **Iteration**: Iterate through each word in each document and reassign the word to a topic based on: the proportion of words in the document that belong to the topic, and the proportion of occurrences of the word across all documents that belong to the topic.\n",
    "   - For each document d:\n",
    "     - For each word w in document d:\n",
    "       - Calculate two probabilities:\n",
    "         - P(topic t | document d): Proportion of words in document d that are currently assigned to topic t.\n",
    "         - P(word w | topic t): Proportion of assignments to topic t over all documents that come from word w.\n",
    "       - Reassign word w to a new topic based on the probabilities calculated above.\n",
    "   \n",
    "   - Repeat the above step for a fixed number of iterations or until convergence.\n",
    "\n",
    "3. **Output**: Repeat step 2 for a certain number of iterations or until convergence. LDA provides two main outputs:\n",
    "   - The distribution of topics in each document.\n",
    "   - The distribution of words in each topic.\n",
    "\n",
    "These distributions can be used to interpret the topics and analyze the relationships between documents and topics.\n",
    "\n",
    "\n",
    "\n",
    "LDA assumes that documents are generated in the following way:\n",
    "- Choose the number of words in the document from a Poisson distribution.\n",
    "- Choose a topic mixture for the document from a Dirichlet distribution.\n",
    "- For each word in the document:\n",
    "  - Choose a topic from the topic mixture.\n",
    "  - Choose a word from the topic's word distribution.\n",
    "\n",
    "LDA is widely used in natural language processing and text mining tasks, such as document clustering, document classification, and information retrieval. It helps uncover the underlying themes or topics in a collection of documents, making it easier to analyze and organize large amounts of textual data[1].\n",
    "\n",
    "Please note that the search results provided additional papers and applications related to LDA, which you can explore for more specific information and use cases.\n",
    "\n",
    "Citations:\n",
    "[1] https://www.semanticscholar.org/paper/b98a4076b48552691bb99290106a378e483cdfca\n",
    "[2] https://www.semanticscholar.org/paper/03ba268430128916e195e8d1a88c761f3c9d7578\n",
    "[3] https://arxiv.org/abs/1309.3421\n",
    "[4] https://www.semanticscholar.org/paper/c80db2cd1b127ec86060ad018c04cd0c48075ae3\n",
    "[5] https://www.semanticscholar.org/paper/1713b2a9291d76c02feb49376422d800d5e44888\n",
    "[6] https://www.semanticscholar.org/paper/59c902e7797889bad1f731205a409ade2913199a\n",
    "\n",
    "\n",
    "The documents can come from any domain as long as they contain text. For example, they could be customer reviews, news articles, research papers, social media posts, etc. The words in the documents are collected into n-grams (a contiguous sequence of n items from a given sample of text or speech) and used to create a dictionary. This dictionary is then used to train the LDA model. \n",
    "\n",
    "It's important to note that the text in the documents should be preprocessed before being used for training the LDA model. This preprocessing can include removing stop words (commonly used words such as 'the', 'a', 'an', 'in'), lowercasing all the words, and lemmatizing the words (reducing inflectional forms and sometimes derivationally related forms of a word to a common base form)\n",
    "\n",
    "When configuring the LDA model, some parameters that can be set include the rho parameter (a prior probability for the sparsity of topic distributions), the alpha parameter (a prior probability for the sparsity of per-document topic weights), the estimated number of documents, the size of the batch, the initial value of iteration used in learning update schedule, the power applied to the iteration during updates, and the number of passes over the data\n",
    "\n",
    "\n",
    "As a result of the training, each document will be represented as a combination of topics, and each topic will be represented as a distribution over words. This can be used to classify new documents, identify related terms, and create recommendations.\n",
    "\n",
    "![LDA](https://www.researchgate.net/profile/Diego-Buenano-Fernandez/publication/339368709/figure/fig1/AS:860489982689280@1582168207260/Schematic-of-LDA-algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5fe482-a1ed-47ce-a18d-e2f6807b3522",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55014f19-2030-4e8f-a44d-1eabff08bc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the number of topics to extract from documents\n",
    "num_topics = 4\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = corpora.Dictionary(lemmatized_train_data)\n",
    "\n",
    "# Create a bag-of-words representation of the documents\n",
    "train_corpus = [dictionary.doc2bow(text) for text in lemmatized_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461a926-5734-49ed-bdd6-61d3e78b377f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# human-readable format of corpus (term-frequency)\n",
    "[[(dictionary[id], freq) for id, freq in cp] for cp in train_corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29786fa-50a0-4530-9eea-7749b303490a",
   "metadata": {},
   "source": [
    "### Gensim version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2490f1e-7e06-4524-913a-a619e0ad125c",
   "metadata": {},
   "source": [
    "Let's build the topic model. I'll define 5 topics to start with. The hyperparameter alpha affects sparsity of the document-topic (theta) distributions, whose default value is 1. Similarly, the hyperparameter eta can also be specified, which affects the topic-word distribution's sparsity.\n",
    "\n",
    "https://www.kaggle.com/code/datajameson/topic-modelling-nlp-amazon-reviews-bbc-news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cabda-e98d-4820-8805-392a792698c0",
   "metadata": {},
   "source": [
    "**Training phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c17fee-75ef-4066-96aa-6429ed741ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the LDA model using the processed training data\n",
    "lda_model = LdaModel(corpus=train_corpus, id2word=dictionary, num_topics=num_topics, random_state=42, passes=10, alpha='auto', per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b505b-303c-43d0-bb3e-741b1d90e580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapping between topic number and category name\n",
    "topic_category_mapping = {\n",
    "    0: 'Religion',\n",
    "    1: 'Car',\n",
    "    2: 'Graphics',\n",
    "    3: 'Space'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b3f129-4ce5-4645-bf32-7f41117dfd56",
   "metadata": {},
   "source": [
    "We explores the trained topics with their main words and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cab14b-21bb-4c13-b7b1-2132cbede10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print topics and associated category names\n",
    "for topic_num, topic in lda_model.show_topics(num_topics=num_topics, formatted=False):\n",
    "    topic_words = [word for word, _ in topic]\n",
    "    category_name = topic_category_mapping.get(topic_num, f'Unknown Category {topic_num}')\n",
    "    print(f\"Topic {topic_num} ({category_name}) | Words: {topic_words}\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b118af9-55a4-4c8b-b9f6-ee30f00c1031",
   "metadata": {},
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, train_corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f19e10-8821-49a3-83fb-3de2698a5724",
   "metadata": {},
   "source": [
    "**Test phase**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c463c-c77d-4c08-b5ee-82e5be21c0b6",
   "metadata": {},
   "source": [
    "Let's now evaluate the model using coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed01c4d-cd3b-4b94-9962-76e23da282e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the coherence score to evaluate the model\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=lemmatized_train_data, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score:', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2cc01-19a6-45e8-94e1-3338e4a33319",
   "metadata": {},
   "source": [
    "Get the topics distributions for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c504d68-c3d6-486a-8a76-6131b19f2a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topic_distribution(lda_model, dictionary, document):\n",
    "    # Preprocess the document\n",
    "    _, preprocessed_document = preprocess_text([document])\n",
    "    # Convert the document into BoW format\n",
    "    bow_document = dictionary.doc2bow(preprocessed_document[0]) # Here we are assuming that preprocessed_document is a list of lists\n",
    "    \n",
    "    # Get the topic distribution\n",
    "    topic_distribution = lda_model.get_document_topics(bow_document, minimum_probability=0.2)\n",
    "    return topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ee1c3-7617-4c1f-8edb-2ed7f7ff7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_topic_distributions = [get_topic_distribution(lda_model, dictionary, text) for text in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3d16a-edd6-4548-9b6c-032c9c2c6960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the topic distribution for all test documents\n",
    "for i, topic_dist in enumerate(test_topic_distributions):\n",
    "    # Sort the topic distribution by probability in descending order\n",
    "    sorted_topic_dist = sorted(topic_dist, key=lambda x: -x[1])\n",
    "    # Create a list to store the formatted topics\n",
    "    formatted_topics = []\n",
    "\n",
    "    # Format and store each topic\n",
    "    for topic_id, probability in sorted_topic_dist:\n",
    "        # Associate label to the topic\n",
    "        category_name = topic_category_mapping.get(topic_id, f'Unknown Category {topic_id}')\n",
    "\n",
    "        formatted_topic = f\"[{topic_id}] {category_name} {probability:.2f}\"\n",
    "        formatted_topics.append(formatted_topic)\n",
    "\n",
    "    # Join the formatted topics into a string\n",
    "    formatted_topics_str = \" - \".join(formatted_topics)\n",
    "\n",
    "    print(f\"Document {i + 1} topics : {formatted_topics_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af18d0f-8342-4493-bd80-c96a57a9ca6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scratch version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff373130-89e5-4e0c-9592-7bc6d4a2cd7a",
   "metadata": {},
   "source": [
    "I implement the LDA model from scratch. The input corpus is in the Gensim bag-of-words format, which is a list of tuples (word index, word count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e045ab-3e4c-4932-8246-df8969ba9afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lda_from_scratch(corpus, num_topics, num_iterations=100, alpha=0.1, beta=0.1):\n",
    "    # Initialize topic assignments randomly\n",
    "    topic_assignments = [[random.randint(0, num_topics - 1) for _ in doc] for doc in corpus]\n",
    "\n",
    "    # Initialize topic-word and document-topic count matrices\n",
    "    num_words = max([word_idx for doc in corpus for word_idx, _ in doc]) + 1\n",
    "    topic_word_counts = np.zeros((num_topics, num_words))\n",
    "    doc_topic_counts = np.zeros((len(corpus), num_topics))\n",
    "\n",
    "    # Count initial topic assignments\n",
    "    for doc_idx, doc in enumerate(corpus):\n",
    "        for word_idx, (word, count) in enumerate(doc):\n",
    "            topic = topic_assignments[doc_idx][word_idx]\n",
    "            topic_word_counts[topic][word] += count\n",
    "            doc_topic_counts[doc_idx][topic] += count\n",
    "\n",
    "    # Perform Gibbs sampling\n",
    "    for it in range(num_iterations):\n",
    "        doc_topic_sums = doc_topic_counts.sum(axis=1)\n",
    "        topic_word_sums = topic_word_counts.sum(axis=1)\n",
    "        \n",
    "        for doc_idx, doc in enumerate(corpus):\n",
    "            for word_idx, (word, count) in enumerate(doc):\n",
    "                # Remove current topic assignment\n",
    "                old_topic = topic_assignments[doc_idx][word_idx]\n",
    "                # Decrement counts for old topic assignment\n",
    "                topic_word_counts[old_topic][word] -= count\n",
    "                doc_topic_counts[doc_idx][old_topic] -= count\n",
    "                doc_topic_sums[doc_idx] -= count\n",
    "                topic_word_sums[old_topic] -= count\n",
    "\n",
    "                # Compute probabilities for each topic (conditional distribution for the word)\n",
    "                p_topic_given_doc = (doc_topic_counts[doc_idx, :] + alpha) / (doc_topic_sums[doc_idx] + num_topics * alpha)\n",
    "                p_word_given_topic = (topic_word_counts[:, word] + beta) / (topic_word_sums + num_words * beta)\n",
    "                probabilities = p_topic_given_doc * p_word_given_topic\n",
    "\n",
    "                # Normalize probabilities\n",
    "                probabilities /= probabilities.sum()\n",
    "\n",
    "                # Sample a new topic assignment\n",
    "                new_topic = np.random.choice(num_topics, p=probabilities)\n",
    "                topic_assignments[doc_idx][word_idx] = new_topic\n",
    "\n",
    "                # Update counts for new topic assignment\n",
    "                topic_word_counts[new_topic][word] += count\n",
    "                doc_topic_counts[doc_idx][new_topic] += count\n",
    "                doc_topic_sums[doc_idx] += count\n",
    "                topic_word_sums[new_topic] += count\n",
    "\n",
    "        print(f\"Iteration {it}\")\n",
    "\n",
    "    return topic_word_counts, doc_topic_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f7293-47fc-4e6b-aa3b-4a246b25cbcc",
   "metadata": {},
   "source": [
    "**Training phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59755ced-43af-4030-b419-93a560e733ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_iterations = 100\n",
    "topic_word_counts, doc_topic_counts = lda_from_scratch(train_corpus, num_topics, num_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bea118-6f3e-402c-9054-50ee1a1d72d2",
   "metadata": {},
   "source": [
    "**Testing phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d3b89-6d32-48ff-8663-feb8d9c3ab06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer_topic_distribution_scratch(document, dictionary, topic_word_counts, doc_topic_counts, alpha=0.1, beta=0.1):\n",
    "    # Preprocess the document\n",
    "    _, preprocessed_document = preprocess_text([document])\n",
    "    # Convert the document into a bag-of-words representation\n",
    "    bow_document = dictionary.doc2bow(preprocessed_document[0])  # Assuming preprocessed_document is a list of lists\n",
    "\n",
    "    num_topics, num_words = topic_word_counts.shape\n",
    "    topic_word_sums = topic_word_counts.sum(axis=1)\n",
    "\n",
    "    doc_topic_counts_inferred = np.zeros(num_topics)\n",
    "    word_topic_distributions = np.zeros((len(bow_document), num_topics))\n",
    "\n",
    "    for i, (word, count) in enumerate(bow_document):\n",
    "        p_topic_given_doc = (doc_topic_counts_inferred + alpha) / (doc_topic_counts_inferred.sum() + num_topics * alpha)\n",
    "        p_word_given_topic = (topic_word_counts[:, word] + beta) / (topic_word_sums + num_words * beta)\n",
    "        probabilities = p_topic_given_doc * p_word_given_topic\n",
    "\n",
    "        # Add a small constant to the probabilities to ensure that every document has at least one topic probability\n",
    "        probabilities += 1e-10\n",
    "\n",
    "        probabilities /= probabilities.sum()\n",
    "\n",
    "        for topic in range(num_topics):\n",
    "            doc_topic_counts_inferred[topic] += count * probabilities[topic]\n",
    "            word_topic_distributions[i, topic] = probabilities[topic]\n",
    "\n",
    "    # Normalize the inferred topic counts before returning, adding a small constant to avoid division by zero\n",
    "    doc_topic_counts_inferred /= (doc_topic_counts_inferred.sum() + 1e-10)\n",
    "    \n",
    "    # Filter out probabilities below the threshold\n",
    "    #doc_topic_counts_inferred = doc_topic_counts_inferred[doc_topic_counts_inferred > 0.2]\n",
    "\n",
    "    return doc_topic_counts_inferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bb77d-6310-4060-9da4-286c3b201c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_topic_distributions = [infer_topic_distribution_scratch(text, dictionary, topic_word_counts, doc_topic_counts) for text in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cd9f9-b81e-4e88-ae04-397f2c697603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the topic distribution for all test documents\n",
    "for i, topic_dist in enumerate(test_topic_distributions):\n",
    "    \n",
    "    # Sort the topic distribution by probability in descending order\n",
    "    sorted_topic_dist = sorted(enumerate(topic_dist), key=lambda x: -x[1])\n",
    "    \n",
    "    # Create a list to store the formatted topics\n",
    "    formatted_topics = []\n",
    "\n",
    "    # Format and store each topic\n",
    "    for topic_id, probability in sorted_topic_dist:\n",
    "        # Exclude probabilities under 0.2\n",
    "        if probability < 0.0:\n",
    "            continue\n",
    "        \n",
    "        # Associate label to the topic\n",
    "        category_name = topic_category_mapping.get(topic_id, f'Unknown Category {topic_id}')\n",
    "\n",
    "        formatted_topic = f\"[{topic_id}] {category_name} {probability:.2f}\"\n",
    "        formatted_topics.append(formatted_topic)\n",
    "\n",
    "    # Join the formatted topics into a string\n",
    "    formatted_topics_str = \" - \".join(formatted_topics)\n",
    "\n",
    "    print(f\"Document {i + 1} topics : {formatted_topics_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb54ca-45d0-48b5-9ce2-0a181a976cd5",
   "metadata": {},
   "source": [
    "I compute the coherence score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434b103-6949-49b2-9802-d1223f285c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "from math import log, exp\n",
    "\n",
    "def compute_coherence_score_scratch_cv(topic_word_counts, lemmatized_corpus, dictionary, top_n=10, window_size=110):\n",
    "    # Get top N words for each topic\n",
    "    top_words = [[dictionary[i] for i in np.argsort(topic_word_counts[t])[-top_n:]] for t in range(len(topic_word_counts))]\n",
    "\n",
    "    # Compute word co-occurrence matrix\n",
    "    co_occurrences = defaultdict(int)\n",
    "    word_counts = defaultdict(int)\n",
    "    for doc in lemmatized_corpus:\n",
    "        for i, word_i in enumerate(doc):\n",
    "            word_counts[word_i] += 1\n",
    "            for j in range(i + 1, min(i + window_size, len(doc))):\n",
    "                word_j = doc[j]\n",
    "                if word_i != word_j:\n",
    "                    co_occurrences[(word_i, word_j)] += 1\n",
    "                    co_occurrences[(word_j, word_i)] += 1\n",
    "\n",
    "    # Compute c_v coherence score\n",
    "    coherence_score = 0\n",
    "    for topic in top_words:\n",
    "        topic_score = 0\n",
    "        for i, word_i in enumerate(topic[:-1]):\n",
    "            for word_j in topic[i+1:]:\n",
    "                if (word_i, word_j) in co_occurrences:\n",
    "                    numerator = co_occurrences[(word_i, word_j)] + 1\n",
    "                    denominator = word_counts[word_i] * word_counts[word_j]\n",
    "                    topic_score += log(numerator / denominator) - log((numerator - 1) / denominator)\n",
    "        coherence_score += topic_score / (top_n * (top_n - 1) / 2)\n",
    "\n",
    "    return coherence_score / len(top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936061a-978f-4b83-821e-a6af5b97fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_score = compute_coherence_score_scratch_cv(topic_word_counts, lemmatized_train_data, dictionary, top_n=1000)\n",
    "print(\"Coherence Score (c_v):\", coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e8145-469a-4c6e-b6af-1227f3e2214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f186f08-494f-48a6-bae9-25f3227d6332",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **4. Sentiment Analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93052d18-4644-4707-9cdb-e6d1fbfb8b52",
   "metadata": {},
   "source": [
    "Determine the sentiment of the content using the VADER sentiment analyzer from the `vaderSentiment`library.\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a pre-trained sentiment analysis tool specifically designed for social media texts and doesn't require preprocessing like tokenization, stemming, or lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7996cfb1-d1fd-467e-909c-26e7c93ca8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to analyze sentiment using VADER\n",
    "def get_sentiment(text):\n",
    "     # Initialize VADER sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = analyzer.polarity_scores(text)\n",
    "    return sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c134384-52d4-4cd5-9f16-471274289860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sentiments = [get_sentiment(text) for text in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64681b6-d2b8-45c3-a847-d77cbc338ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the sentiment scores for the first 10 test documents\n",
    "scores_list = []\n",
    "for i, sentiment in enumerate(test_sentiments):\n",
    "    scores_list.append(sentiment['compound'])\n",
    "    print(f\"Document {i + 1}: {sentiment}\")\n",
    "    \n",
    "print(f\"\\nAverage sentiment: {np.mean(scores_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d695c42-a3fb-4286-80b4-11ed8777db26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebc9b40b-c510-49bd-b001-4b5bb262c9fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **5. Summarization:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97070c92-b042-4a39-aaaf-a1d5e61c73bd",
   "metadata": {},
   "source": [
    "Generate summaries of the relevant content using extractive summarization based on word frequency. For this, I'll follow these steps:\n",
    "- 1. Split the text into sentences.\n",
    "- 2. Tokenize the sentences.\n",
    "- 3. Calculate the frequency of each word in the text.\n",
    "- 4. Assign a score to each sentence based on the frequency of the words in the sentence.\n",
    "- 5. Select the top N sentences with the highest scores as the summary.\n",
    "\n",
    "This is a simple implementation of extractive summarization without using any libraries. Note that this approach does not consider the semantic meaning of words or the coherence of the summary. More advanced techniques, such as using word embeddings or graph-based methods, can improve the quality of the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22165272-7b33-4c13-aed1-10fd61c61d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractive_summarization(text, n_sentences=3):\n",
    "    # Split the text into sentences\n",
    "    sentences = text.strip().split('.')\n",
    "\n",
    "    # Tokenize and preprocess the text\n",
    "    word_freq = {}\n",
    "    for sentence in sentences:\n",
    "        stemmed_tokens, _ = preprocess_text([sentence])\n",
    "        # Flatten the stemmed_tokens list\n",
    "        stemmed_tokens = [token for sublist in stemmed_tokens for token in sublist]\n",
    "        for token in stemmed_tokens:\n",
    "            if token not in word_freq:\n",
    "                word_freq[token] = 1\n",
    "            else:\n",
    "                word_freq[token] += 1\n",
    "\n",
    "    # Calculate the score for each sentence\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        stemmed_tokens, _ = preprocess_text([sentence])\n",
    "        # Flatten the stemmed_tokens list\n",
    "        stemmed_tokens = [token for sublist in stemmed_tokens for token in sublist]\n",
    "        for token in stemmed_tokens:\n",
    "            if token in word_freq:\n",
    "                if sentence not in sentence_scores:\n",
    "                    sentence_scores[sentence] = word_freq[token]\n",
    "                else:\n",
    "                    sentence_scores[sentence] += word_freq[token]\n",
    "\n",
    "    # Select the top N sentences with the highest scores\n",
    "    summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:n_sentences]\n",
    "    summary = '. '.join(summary_sentences)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791a142-a079-4db3-b720-e47f5a2d6733",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summaries = [extractive_summarization(text, n_sentences=1) for text in test_data]\n",
    "\n",
    "# Print summary for every document in the test set\n",
    "for i, summary in enumerate(summaries):\n",
    "    print(f\"Summary {i + 1}: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044b883-3b05-4b3f-a414-ecc8e4509ec9",
   "metadata": {},
   "source": [
    "# **6. Visualization and Reporting:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed63a74-5413-4146-ab80-b6fdad05b897",
   "metadata": {},
   "source": [
    "Visualize the results in an intuitive dashboard or report format, showing the distribution of topics, sentiment scores, and summaries of the relevant content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d055d9d-8caf-4b2f-b490-309d27aaa9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge all the texts in the test set\n",
    "merged_test_text = ' '.join(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46818890-8183-444f-8d75-b3432b1d897e",
   "metadata": {},
   "source": [
    "## Main topic\n",
    "In this section I print the main topic identified from all the documents in the test set, so from 100 different texts, using the LDA model from gensim and my own implementation. The test set is composed by 70% space topic, so what I expect is that the model will gives me \"Space\" as main topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c6c23-4111-40f8-b55a-12b7805aac95",
   "metadata": {},
   "source": [
    "### Gensim version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c928a2-a91d-4550-9c60-55ebb242ab06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the topic distribution for the merged text\n",
    "merged_text_topic_distribution = get_topic_distribution(lda_model, dictionary, merged_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2e3c4-306d-44bb-9d91-3c915b24bf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"\\nMain topics distribution:\")\n",
    "\n",
    "# Display the topic distribution for all test documents\n",
    "for i, topic_dist in enumerate(merged_text_topic_distribution):\n",
    "    sorted_topic_dist = sorted([topic_dist], key=lambda x: -x[1])\n",
    "    formatted_topics = []\n",
    "    for topic_id, probability in sorted_topic_dist:\n",
    "        topic_name = topic_category_mapping.get(topic_id, f'Unknown Category {topic_id}')\n",
    "        formatted_topic = f\"[{topic_id}] {topic_name} -> {probability}\"\n",
    "        formatted_topics.append(formatted_topic)\n",
    "        formatted_topics_str = \" - \".join(formatted_topics)\n",
    "    print(f\"{formatted_topics_str}\")\n",
    "\n",
    "# Identify the main topic based on the highest average topic distribution\n",
    "main_topic = max(merged_text_topic_distribution, key=lambda x: x[1])[0]\n",
    "topic_name = topic_category_mapping.get(main_topic, f'Unknown Category {topic_num}')\n",
    "\n",
    "# Display the main topic keywords\n",
    "main_topic_keywords = lda_model.show_topic(main_topic)\n",
    "print(f\"\\nMain {topic_name} keywords:\\n{main_topic_keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67b287-de9a-4970-918d-01b97bc88173",
   "metadata": {},
   "source": [
    "### Scratch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070a50f-3644-4630-b179-7991d97f107e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_category_mapping_scratch = {\n",
    "    0: 'Religion',\n",
    "    1: 'Space',\n",
    "    2: 'Car',\n",
    "    3: 'Graphic'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a676a4-4d85-432f-b828-aa83170afd75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the topic distribution for the document\n",
    "topic_distribution = infer_topic_distribution_scratch(merged_test_text, dictionary, topic_word_counts, doc_topic_counts, alpha=0.1, beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e7b11-a1d1-4a59-b941-bbee09ba06c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"\\nMain topics distribution:\")\n",
    "\n",
    "# Display the topic distribution\n",
    "sorted_topic_dist = sorted(enumerate(topic_distribution), key=lambda x: -x[1])\n",
    "for topic_id, probability in sorted_topic_dist:\n",
    "    # Exclude probabilities under 0.2\n",
    "    #if probability < 0.2:\n",
    "    #    continue\n",
    "\n",
    "    topic_name = topic_category_mapping_scratch.get(topic_id, f'Unknown Category {topic_id}')\n",
    "    formatted_topic = f\"[{topic_id}] {topic_name} -> {probability}\"\n",
    "    print(formatted_topic)\n",
    "\n",
    "# Identify the main topic based on the highest probability\n",
    "main_topic = sorted_topic_dist[0][0]\n",
    "topic_name = topic_category_mapping_scratch.get(main_topic, f'Unknown Category {main_topic}')\n",
    "\n",
    "# Display the main topic keywords\n",
    "main_topic_keywords = []\n",
    "for word, _ in sorted(enumerate(topic_word_counts[main_topic]), key=lambda x: -x[1])[:15]:\n",
    "    main_topic_keywords.append(dictionary[word])\n",
    "print(f\"\\nMain {topic_name} keywords:\\n{main_topic_keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d00bc-bec8-4128-8366-861f1dcf1c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cabd4c72-8148-4b4e-bf1b-3dece9cc4867",
   "metadata": {},
   "source": [
    "## Average sentiment\n",
    "In this section I print the average of all the documents in the test set, and I display the sentiments scores using a bar-chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b542c4c-9b6f-4317-86db-df392c21ed7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_text_sentiment = get_sentiment(merged_test_text)\n",
    "\n",
    "print(f\"Global Text Sentiment: {merged_text_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511cf406-345f-40d0-9f83-33e1618ec4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to visualize sentiment scores\n",
    "def visualize_sentiment(sentiment_scores):\n",
    "    labels = ['Positive', 'Neutral', 'Negative']\n",
    "    values = [sentiment_scores['pos'], sentiment_scores['neu'], sentiment_scores['neg']]\n",
    "\n",
    "    plt.bar(labels, values)\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Sentiment Analysis')\n",
    "    plt.show()\n",
    "    \n",
    "visualize_sentiment(merged_text_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6db6d-4211-4af8-bc32-cca1494e34ed",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this section I print a summary of all documents the test set, showing the relevant phrases from all the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1f6ef-e80b-41b9-8acb-7b7f956dec99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = extractive_summarization(merged_test_text, n_sentences=3)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e465cbe7-7e5f-4906-bad7-d85e43e0ab03",
   "metadata": {},
   "source": [
    "## Word distribution\n",
    "In this section I show the most frequent words in the test set. Bigger are the words showed, higher is their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905634a2-65a2-4901-8503-238999bc3fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to generate a word cloud\n",
    "def generate_wordcloud(texts):\n",
    "    all_text = ' '.join(texts)\n",
    "    wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=5, max_words=100).generate(all_text)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud of Texts')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed98675-3a29-4103-960b-b83ecf221bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate word cloud\n",
    "generate_wordcloud([merged_test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb9713-1938-4169-b8e1-ae7e36e9b32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74377c-6310-4b3a-b2db-b68be4cbb13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e6704-9bee-447a-ba5e-54bccebe7027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b273e-8131-44c9-bd52-7cbf6000f43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721a5f2-71ba-4394-ba63-ce81ae1683fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd15b3-f2f2-4d6a-80e6-8d07a088efab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b5b29-b75c-45b0-b8c9-46be8762f126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b7f83-085f-43c2-b664-632e0afb7915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ed18c-26f9-4993-a7f4-982cf7d6bc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
